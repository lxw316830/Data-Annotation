import os
import hashlib
import shutil
from typing import List


def remove_duplicate_images_and_limit(
        file_list: List[str],
        source_folder: str,
        target_folder: str,
        max_files: int = 300
) -> None:
    """
    å»é™¤é‡å¤å›¾ç‰‡ï¼Œå¹¶å°†æœ€å¤š max_files ä¸ªä¸é‡å¤çš„å›¾ç‰‡å¤åˆ¶åˆ°ç›®æ ‡æ–‡ä»¶å¤¹ã€‚

    :param file_list: å›¾ç‰‡æ–‡ä»¶ååˆ—è¡¨ï¼ˆå¦‚ ['a.jpg', 'b.png']ï¼‰
    :param source_folder: æºæ–‡ä»¶å¤¹è·¯å¾„
    :param target_folder: ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„
    :param max_files: æœ€å¤šä¿ç•™å¤šå°‘ä¸ªæ–‡ä»¶
    """
    seen_hashes = set()
    unique_files = []

    # ç¡®ä¿ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(target_folder, exist_ok=True)

    for file_name in file_list:
        if len(unique_files) >= max_files:
            break

        file_path = os.path.join(source_folder, file_name)

        # è·³è¿‡éæ–‡ä»¶ï¼ˆå¦‚å­ç›®å½•ï¼‰
        if not os.path.isfile(file_path):
            continue

        try:
            # è®¡ç®— MD5 å“ˆå¸Œ
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            file_hash = hash_md5.hexdigest()

            if file_hash not in seen_hashes:
                seen_hashes.add(file_hash)
                unique_files.append(file_name)  # ä¿ç•™æ–‡ä»¶å

                # å¤åˆ¶åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
                dest_path = os.path.join(target_folder, file_name)
                shutil.copy2(file_path, dest_path)  # copy2 ä¿ç•™å…ƒæ•°æ®
                print(f"å·²å¤åˆ¶: {file_name}")

        except Exception as e:
            print(f"è·³è¿‡æ–‡ä»¶ {file_name}: {e}")
            continue

    print(f"\nâœ… å»é‡å®Œæˆï¼å…±ä¿ç•™ {len(unique_files)} ä¸ªä¸é‡å¤å›¾ç‰‡ã€‚")
    print(f"ğŸ“ ç›®æ ‡æ–‡ä»¶å¤¹: {target_folder}")


# ================== é…ç½®è·¯å¾„ ==================
source_dir = r"C:\Users\33908\Documents\æ–‡æ¡£\date\yolo-seg-å”æ–‡é¾™\img\yyzz"
target_dir = r"C:\Users\33908\Documents\pycharm\ä¿å®š25.9.09æ™ºæ…§ç½‘åŠ\information_extraction\uie_date\yyzz"  # ä¿®æ”¹è¿™é‡Œ

# è·å–æºæ–‡ä»¶å¤¹ä¸­æ‰€æœ‰æ–‡ä»¶
file_names = os.listdir(source_dir)

# æ‰§è¡Œå»é‡å¹¶å¤åˆ¶
remove_duplicate_images_and_limit(
    file_list=file_names,
    source_folder=source_dir,
    target_folder=target_dir,
    max_files=300
)